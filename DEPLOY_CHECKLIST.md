# ðŸš€ Deployment Checklist

## Pre-flight Checks

### 1. Environment Variables
Check your `.env` file has these values:
- [ ] `OPENROUTER_API_KEY` - Your OpenRouter API key
- [ ] `SLACK_WEBHOOK_URL` - Your Slack webhook URL
- [ ] `GOOGLE_CLOUD_PROJECT` - Your GCP project ID (or will be set during deploy)

### 2. Google Cloud Setup
- [ ] Google Cloud account created
- [ ] Billing enabled (but will use free tier)
- [ ] Project created

### 3. Fix gcloud PATH
If `gcloud auth login` fails, run:
```bash
export PATH="$HOME/google-cloud-sdk/bin:$PATH"
```

## Deployment Steps

### Option 1: Automated Deployment (Recommended)
```bash
# Run the production deployment script
./deploy_production.sh
```

This script will:
1. Check gcloud authentication
2. Verify project settings
3. Check Firestore (uses default database)
4. Enable required APIs
5. Deploy your chosen configuration

### Option 2: Manual Deployment

#### Step 1: Authenticate
```bash
export PATH="$HOME/google-cloud-sdk/bin:$PATH"
gcloud auth login
gcloud config set project YOUR_PROJECT_ID
```

#### Step 2: Enable APIs
```bash
gcloud services enable cloudfunctions.googleapis.com
gcloud services enable firestore.googleapis.com
gcloud services enable cloudscheduler.googleapis.com
gcloud services enable pubsub.googleapis.com
```

#### Step 3: Deploy Function
```bash
# For digest version (single daily post)
gcloud functions deploy ai-news-digest \
  --runtime=python311 \
  --trigger-topic=ai-news-trigger \
  --entry-point=main_function_digest \
  --source=. \
  --memory=512MB \
  --timeout=540s \
  --env-vars-file=.env \
  --region=us-central1
```

#### Step 4: Create Schedule
```bash
# Daily at 7 AM MST
gcloud scheduler jobs create pubsub ai-news-daily \
  --schedule="0 7 * * *" \
  --time-zone="America/Denver" \
  --topic=ai-news-trigger \
  --message-body='{"trigger":"scheduled"}' \
  --location=us-central1
```

## Post-Deployment

### Test Your Deployment
```bash
# Trigger manually
gcloud pubsub topics publish ai-news-trigger --message='test'

# Check logs
gcloud functions logs read ai-news-digest --limit=50
```

### Monitor
- Cloud Console: https://console.cloud.google.com/functions
- Logs: `gcloud functions logs read --limit=50`
- Firestore: https://console.cloud.google.com/firestore

## Troubleshooting

### "gcloud: command not found"
```bash
export PATH="$HOME/google-cloud-sdk/bin:$PATH"
echo 'export PATH="$HOME/google-cloud-sdk/bin:$PATH"' >> ~/.bashrc
```

### Authentication Issues
```bash
gcloud auth login --no-launch-browser
# Copy the URL and authenticate in your browser
```

### Firestore Issues
Your Firestore is using `(default)` database, which is perfect. The functions will automatically create the `processed_items` collection.

### Function Timeout
If processing takes too long, posts partial digest. This is by design to ensure some content is delivered.

## Environment Variables Reference

| Variable | Description | Where to Get |
|----------|-------------|--------------|
| `OPENROUTER_API_KEY` | OpenRouter API key | https://openrouter.ai/keys |
| `SLACK_WEBHOOK_URL` | Slack incoming webhook | https://api.slack.com/apps |
| `GOOGLE_CLOUD_PROJECT` | GCP project ID | https://console.cloud.google.com |
| `ENVIRONMENT` | `production` or `development` | Set automatically |
| `FIRESTORE_COLLECTION` | `processed_items` | Set automatically |